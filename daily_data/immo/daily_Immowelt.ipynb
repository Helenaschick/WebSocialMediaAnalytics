{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tägliches Immowelt Webscraping\n",
    "\n",
    "In diesem zweiten Notebook wird der Webscraping Code des ersten Notebooks, Web Analytics Project, angewendet und das Skript läuft täglich auf einem aws EC2 Server und speichert die gescrapten Daten je in eine neue Datei. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inhaltsverzeichnis\n",
    "\n",
    "1. [Installationen](#1-installationen)\n",
    "2. [URL Untersuchung](#2-url-untersuchung)\n",
    "3. [Webscraping](#3-webscraping)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installationen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import lxml\n",
    "from lxml import html\n",
    "from lxml import etree\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "import csv\n",
    "from csv import writer\n",
    "\n",
    "from scipy import stats\n",
    "from datetime import date\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. URL Untersuchung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Daten die abgefragt werden dedfinieren\n",
    "Ort = [\"berlin\", \"frankfurt-am-main\", \"hamburg\", \"koeln\", \"leipzig\", \"muenchen\", \"stuttgart\"]\n",
    "Umkreis = 50\n",
    "Objekt = [\"haeuser\"]\n",
    "Seite = list(range(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. URL aufteilen\n",
    "Website = \"https://www.immowelt.de/liste/\"\n",
    "Slash = \"/\"\n",
    "Snippet1 = \"/kaufen?d=true&efs=NEW_BUILDING_PROJECT&efs=JUDICIAL_SALE&r=\"\n",
    "Snippet2 = \"&sd=DESC&sf=RELEVANCE&sp=\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Webscraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UPDATE SCHLEIFE\n",
    "\n",
    "#12. Das ganze Automatisiert\n",
    "#funktioniert alles Perfekt mit Fläche und Räume auch wenn manchmal nichts eingetragen ist\n",
    "# wenn nichts eingetragen ist, ist der Eintrag leer\n",
    "#csv Datei wird ausgegeben in dem Ordner wo es gespeichert ist\n",
    "#es fehlt nur noch die maximale Seitenanzahl vom Button. Den auslesen und dann in die Schleifen einbinden\n",
    "#weil bisher nur händische Eingabe der Seitenanzahl. Die Seitenanzahl ist mal auf zwei Seiten pro Suche \n",
    "#hier eingestellt\n",
    "#benötigt etwas mehr als 15 Minuten\n",
    "\n",
    "\n",
    "#ab hier bis zum nächsten hier ist 11.2 vorgeschaltet\n",
    "AnzahlElementebyID=0\n",
    "\n",
    "a = [[0 for j in range(len(Ort)*len(Seite)+10)] for i in range(len(Ort)*len(Seite)+10)]\n",
    "for i in range(len(Ort)):\n",
    "    for j in range(len(Seite)):\n",
    "        a[i][j]= Website + Ort[i] + Slash + Objekt[0] +Snippet1 + str(Umkreis) + Snippet2 + str(Seite[j]+1)\n",
    "        page = requests.get(a[i][j])\n",
    "        tree = html.fromstring(page.content)\n",
    "        id = tree.xpath(\".//a/@id\")\n",
    "        \n",
    "        AnzahlElementebyID=AnzahlElementebyID+len(id)\n",
    "#hier \n",
    "\n",
    "\n",
    "#dann die Ausgabe definieren alles wie oben (Punkt 1. bis 11.) bis darauf, \n",
    "#dass alles in der Matrix b gespeichert wird \n",
    "#die Matrix b hat als Länge der Zeilen die Gesamtanzahl der Objekte über alle Seiten (AnzahlElementebyID)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#[[0 for j in range(Anzahl Spalten)] for i in range(Anzahl Zeilen)]; \n",
    "#a[i][j]=a[Zeile][Spalte]=AnzahlElementebyIDert in Zelle der Zeile i und Spalte j\n",
    "b = [[0 for s in range(15)] for r in range(len(Ort)*AnzahlElementebyID)]\n",
    "a = [[0 for j in range(len(Ort)*len(Seite)+10)] for i in range(len(Ort)*len(Seite)+10)]\n",
    "laenge = 0\n",
    "for i in range(len(Ort)):    \n",
    "    for j in range(len(Seite)):\n",
    "        a[i][j]= Website + Ort[i] + Slash + Objekt[0] +Snippet1 + str(Umkreis) + Snippet2 + str(Seite[j]+1)\n",
    "        page = requests.get(a[i][j])\n",
    "        tree = html.fromstring(page.content)\n",
    "        id = tree.xpath(\".//a/@id\")\n",
    "        prices = tree.xpath('//div[@data-test=\"price\"]/text()')\n",
    "        MaxOrt = tree.xpath('//div[@class=\"estateFacts-f11b0\"]/div[1]/span/text()')\n",
    "        for e in range(len(MaxOrt)):\n",
    "            MaxOrt[e]=MaxOrt[e][MaxOrt[e].index(\"\"): MaxOrt[e].index(\"|\")-1] \n",
    "        \n",
    "        rooms = [[0 for s in range(1)] for r in range(len(id))]\n",
    "        area= [[0 for s in range(1)] for r in range(len(id))]\n",
    "        \n",
    "        for e in range(len(id)):\n",
    "            rooms[e][0]= tree.xpath('//a[@id=\"%s\"]/div[2]/div[1]/div[1]/div[3]/text()'% id[e])\n",
    "            area[e][0]= tree.xpath('//a[@id=\"%s\"]/div[2]/div[1]/div[1]/div[2]/text()'% id[e])\n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        for r in range(len(id)):\n",
    "             b[laenge+r][0]= id[r] \n",
    "             b[laenge+r][1]= MaxOrt[r]     \n",
    "             b[laenge+r][2]= prices[r]      \n",
    "             b[laenge+r][3]= Ort[i]\n",
    "             b[laenge+r][4]=Umkreis\n",
    "             b[laenge+r][5]= area[r][0]\n",
    "             b[laenge+r][6]= rooms[r][0]\n",
    "             \n",
    "             \n",
    "           \n",
    "             \n",
    "        #laenge ist die Aktuelle Anzahl Häusern in der For Schleife \n",
    "        # for r in range(len(id)): für die erste Seite fängt es bei b[0+r][Beliebiger Platzhalter] an dann \n",
    "        # die zweite Seite ist die Häuseranzahl der ersten Seite laenge=0+len(id) also z.B laenge=20\n",
    "        # dann fängt für die zweite Seite die b Matrix bei b[20+r][beliebiger Platzhalter] an und geht für\n",
    "        # r = len(id) also die Anzahl der Häuser ab und addiert diese auf den letzten Wert der vorherigen Seite \n",
    "        # siehe  b[laenge+r][Beliebiger Platzhalter]  \n",
    "        laenge = laenge + len(id) \n",
    "        \n",
    "              \n",
    "#Die Daten von der Einzelseite des Objekts scrapen\n",
    "\n",
    "haus_url= [[0 for j in range(100000)] for i in range(AnzahlElementebyID+100)]\n",
    "website = \"https://www.immowelt.de/expose/\"\n",
    "\n",
    "for i in range(AnzahlElementebyID):\n",
    "    haus_url[0][i] = website + str(b[i][0])\n",
    "    \n",
    "#for i in range(len(AnzahlElementebyID)):\n",
    "    #print(haus_url[0][i])\n",
    "    \n",
    "for i in range(AnzahlElementebyID):    \n",
    "    expose = requests.get(haus_url[0][i])\n",
    "    ex_tree = html.fromstring(expose.content) \n",
    "    \n",
    "    Grundstücksfläche= ex_tree.xpath(\".//p[text()='Grundstücksfläche']\")\n",
    "    Kategorie= ex_tree.xpath(\".//p[text()='Kategorie']\")\n",
    "    Etagen= ex_tree.xpath(\".//p[text()='Geschosse']\")\n",
    "    Baujahr= ex_tree.xpath(\".//p[text()='Baujahr']\")\n",
    "    Effizienzklasse= ex_tree.xpath(\".//p[text()='Effizienzklasse']\")\n",
    "    Energieträger= ex_tree.xpath(\".//p[text()='Energieträger']\")\n",
    "    Heizungsart= ex_tree.xpath(\".//p[text()='Heizungsart']\")\n",
    "    \n",
    "     \n",
    "    b[i][7]= ex_tree.xpath('//div[@class=\"flex ng-star-inserted\"]/div[3]/span/text()') \n",
    "        \n",
    "    \n",
    "    if (len(Kategorie)) >= 1:  \n",
    "        b[i][8] = ex_tree.xpath('//sd-cell-col[(@class=\"cell__col\") and (.//p[text()=\"Kategorie\"])]/p[2]/text()')\n",
    "    else: \n",
    "        b[i][8]= \"n.a\" \n",
    "    \n",
    "    if (len(Etagen)) >= 1:  \n",
    "        b[i][9] = ex_tree.xpath('//sd-cell-col[(@class=\"cell__col\") and (.//p[text()=\"Geschosse\"])]/p[2]/text()')\n",
    "    else:\n",
    "        b[i][9]= \"n.a\" \n",
    "\n",
    "    if (len(Baujahr)) >= 1:  \n",
    "        b[i][10]= ex_tree.xpath('//sd-cell-col[(@class=\"cell__col\") and (.//p[text()=\"Baujahr\"])]/p[2]/text()')\n",
    "    else:\n",
    "        b[i][10]= \"n.a\" \n",
    "   \n",
    "    if (len(Effizienzklasse)) >= 1:  \n",
    "        b[i][11] = ex_tree.xpath('//sd-cell-col[(@class=\"cell__col\") and (.//p[text()=\"Effizienzklasse\"])]/p[2]/text()')\n",
    "    else: \n",
    "        b[i][11]= \"n.a\" \n",
    "   \n",
    "    if (len(Energieträger)) >= 1:  \n",
    "        b[i][12] = ex_tree.xpath('//sd-cell-col[(@class=\"cell__col\") and (.//p[text()=\"Energieträger\"])]/p[2]/text()')\n",
    "    else:\n",
    "        b[i][12]= \"n.a\"\n",
    "    \n",
    "    if (len(Heizungsart)) >= 1:  \n",
    "        b[i][13] = ex_tree.xpath('//sd-cell-col[(@class=\"cell__col\") and (.//p[text()=\"Heizungsart\"])]/p[2]/text()')\n",
    "    else:\n",
    "      b[i][13]= \"n.a\"  \n",
    "   \n",
    "#jetzt noch in CSV Datei ausgeben:     \n",
    "\n",
    "data = {\n",
    "    'ID': [],\n",
    "    'Ort': [],\n",
    "    'Umkreis': [],\n",
    "    'MaxOrt': [],\n",
    "    'Preis': [],\n",
    "    'Fläche': [],\n",
    "    'Zimmer': [],\n",
    "    'Grundstücksfläche': [],\n",
    "    'Kategorie': [],\n",
    "    'Etagen': [],\n",
    "    'Baujahr': [],\n",
    "    'Effizienzklasse': [],\n",
    "    'Energieträger': [],\n",
    "    'Heizungsart': [],\n",
    "    'Stand':[],\n",
    "}\n",
    "\n",
    "for q in range(AnzahlElementebyID):\n",
    "    data['ID'].append(b[q][0])\n",
    "    data['Ort'].append(b[q][3])\n",
    "    data['Umkreis'].append(b[q][4])\n",
    "    data['MaxOrt'].append(b[q][1])\n",
    "    data['Preis'].append(b[q][2])\n",
    "    data['Fläche'].append(b[q][5])\n",
    "    data['Zimmer'].append(b[q][6])\n",
    "    data['Grundstücksfläche'].append(b[q][7])\n",
    "    data['Kategorie'].append(b[q][8])\n",
    "    data['Etagen'].append(b[q][9])\n",
    "    data['Baujahr'].append(b[q][10])\n",
    "    data['Effizienzklasse'].append(b[q][11])\n",
    "    data['Energieträger'].append(b[q][12]) \n",
    "    data['Heizungsart'].append(b[q][13]) \n",
    "    data['Stand'].append(date.today())\n",
    "      \n",
    "     \n",
    "     \n",
    "     \n",
    "     \n",
    "df=pd.DataFrame(data, columns=['ID','Ort','Umkreis','MaxOrt','Preis','Fläche','Zimmer','Grundstücksfläche','Kategorie','Etagen','Baujahr','Effizienzklasse','Energieträger','Heizungsart','Stand']) \n",
    "df.to_csv(str(date.today()) +'_Immobilien.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 18:24:45) \n[Clang 12.0.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
